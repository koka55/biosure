{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1 - Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from google.colab import drive\n",
    "import json\n",
    "import pandas as pd\n",
    "import math\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2 - Core Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERTS DICTIONARIES TAKEN FROM .JSON FILES INTO DATAFRAMES FOR THE KEY EVENTS\n",
    "def dict_key_conversion(data):\n",
    "    temp_df = pd.DataFrame(columns=['test_number', 'dwell_time', 'flight_time', 'key_pressed'])\n",
    "    temp_flight_df = pd.DataFrame(columns=['test_number', 'flight_time', 'key_released'])\n",
    "\n",
    "    temp_df_count = 0 # indicates which row of the df the next row of data should be appeneded into\n",
    "    temp_flight_df_count = 0\n",
    "\n",
    "    for i in range(1, 11): # loops through each of the tests in true_data\n",
    "        k_data = data['test_'+str(i)]['key_events']\n",
    "        # removes tabs from the data, as kivy, which is the library used for data collection, doesn't register tab releases, only presses\n",
    "        tabless_k_data = []\n",
    "        for k in k_data:\n",
    "            if k['Key'] != 'tab':\n",
    "                tabless_k_data.append(k)\n",
    "\n",
    "        count = 0 #counter for how many iterations into the for loop it is\n",
    "        f_count = 0 #counter for how many iterations into the loop the flight section has done\n",
    "        prev_key_press = 0\n",
    "        prev_key_release = 0\n",
    "        for j in tabless_k_data:\n",
    "            if j['Event'] == 'pressed': # THIS EXECUTES TO FIND THE DWELL TIME\n",
    "                flight_impute = 0 # imputes flight time as 0 for now, as there are instances of key presses not having releases at the end of the test\n",
    "                key_id = j['Key'] # this is what the actual key that is being pressed/released is\n",
    "                key_press_time = j['Epoch'] # the epoch time of the key press\n",
    "                key_release = False # is true when the release of the key has been found\n",
    "                cont_count = 1 # keeps track of counting from the current key press, as it loops from\n",
    "\n",
    "                while key_release == False: # continues\n",
    "                    c = cont_count + count\n",
    "                    start_row = tabless_k_data[count]\n",
    "                    next_row = tabless_k_data[c]\n",
    "                    # executes if the row is the release of the key that was pressed, and exits the while loop\n",
    "                    if next_row['Key'] == key_id and next_row['Event'] == 'released':\n",
    "                        key_release_time = next_row['Epoch']\n",
    "                        dwell_time = float(key_release_time) - float(key_press_time)\n",
    "                        key_release = True\n",
    "                    # executes if the next row is a press event for a different key\n",
    "                    elif next_row['Key'] != key_id and next_row['Event'] == 'pressed':\n",
    "                        cont_count += 1\n",
    "                    elif next_row['Key'] != key_id and next_row['Event'] == 'released':\n",
    "                        cont_count += 1\n",
    "                    else:\n",
    "                        key_release = True\n",
    "                        dwell_time = 0\n",
    "                        key_release_time = start_row['Epoch']\n",
    "\n",
    "                temp_df.loc[temp_df_count] = [i, dwell_time, flight_impute, key_id]\n",
    "\n",
    "                prev_key_press = key_press_time\n",
    "                prev_key_release = key_release_time\n",
    "                temp_df_count += 1\n",
    "\n",
    "            count += 1\n",
    "\n",
    "            if j['Event'] == 'released': # THIS EXECUTES TO FIND THE FLIGHT TIME\n",
    "                key_id = j['Key']\n",
    "                f_cont_count = 1\n",
    "                flight_time = []\n",
    "                flight_found = False\n",
    "                while flight_found == False:\n",
    "                    f_c = f_count + f_cont_count\n",
    "                    if f_c < len(tabless_k_data):\n",
    "                        next_row = tabless_k_data[f_c]\n",
    "                        if next_row['Event'] == 'pressed' and next_row['Key'] != key_id:\n",
    "                            flight_time = float(next_row['Epoch']) - float(j['Epoch'])\n",
    "                            temp_flight_df.loc[temp_flight_df_count] = [i, flight_time, key_id]\n",
    "                            temp_flight_df_count += 1\n",
    "                            flight_found = True\n",
    "                        f_cont_count += 1\n",
    "                    else:\n",
    "                        flight_found = True\n",
    "            f_count += 1\n",
    "\n",
    "    # Now merges the flight time df with the rest of the features\n",
    "    for i in range(1, 11):\n",
    "        fh_count = 0\n",
    "        flight_hold = []\n",
    "        for j in temp_flight_df.index:\n",
    "            if temp_flight_df.at[j, 'test_number'] == i:\n",
    "                flight_hold.append(temp_flight_df.at[j, 'flight_time'])\n",
    "        fh_count = 0\n",
    "\n",
    "        for j in temp_df.index:\n",
    "            if temp_df.at[j, 'test_number'] == i and fh_count < len(flight_hold):\n",
    "                temp_df.at[j, 'flight_time'] = flight_hold[fh_count]\n",
    "                fh_count += 1\n",
    "\n",
    "    true_k_df = temp_df\n",
    "    return true_k_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Mouse Trajectory and Duration Calculation for Event-Based Data\n",
    "\n",
    "# Method to calculate the distance between two coordinates\n",
    "def get_distance(a, b):\n",
    "    distance = math.sqrt(((a[0] - b[0]) ** 2) + ((a[1] - b[1]) ** 2))\n",
    "    return distance\n",
    "\n",
    "# Modified function to calculate mouse events and duration\n",
    "def dict_mouse_conversion(data):\n",
    "    m_df = pd.DataFrame(columns=['test_number', 'movement_id', 'trajectory', 'mouse_duration', 'single_coor'])\n",
    "    row_count = 0\n",
    "\n",
    "    for i in range(1, 11):  # Iterate over each test\n",
    "        m_data = data['test_'+str(i)]['mouse_events']\n",
    "        m_movements = []\n",
    "\n",
    "        # Collect all mouse movements\n",
    "        for j in m_data[:len(m_data)-1]:\n",
    "            if j['Event'] == 'movement':\n",
    "                m_movements.append(j)\n",
    "\n",
    "        # Create a dictionary to store coordinates for each movement ID\n",
    "        movement_coor_dict = {}\n",
    "        for j in m_movements:\n",
    "            movement_coor_dict[j['Movement ID']] = []\n",
    "\n",
    "        for j in m_movements:\n",
    "            movement_coor_dict[j['Movement ID']].append(j['Coordinates'])\n",
    "\n",
    "        # Calculate trajectory length and mouse event duration for each movement ID\n",
    "        for j in movement_coor_dict:\n",
    "            coor_list = movement_coor_dict[j]\n",
    "            motion_start = False\n",
    "            trajectory = 0\n",
    "            mouse_duration = 0\n",
    "\n",
    "            # If there are multiple coordinates, calculate trajectory and duration\n",
    "            if len(coor_list) > 1:\n",
    "                trajectory_list = []\n",
    "                time_stamps = []  # To store event timestamps for duration calculation\n",
    "\n",
    "                # Calculate distance between each pair of consecutive coordinates\n",
    "                for k in range(1, len(coor_list)):\n",
    "                    trajectory_list.append(get_distance(coor_list[k-1], coor_list[k]))\n",
    "                    time_stamps.append(m_movements[k]['Epoch'])  # Collect timestamps\n",
    "\n",
    "                movement_id = j\n",
    "                trajectory = sum(trajectory_list)\n",
    "\n",
    "                # Calculate mouse duration as the difference between the last and first timestamp\n",
    "                mouse_duration = float(time_stamps[-1]) - float(time_stamps[0])\n",
    "                single_coor = False\n",
    "            else:\n",
    "                movement_id = j\n",
    "                trajectory_list = [0]\n",
    "                trajectory = 0\n",
    "                mouse_duration = 0\n",
    "                single_coor = True\n",
    "\n",
    "            # Add the calculated values to the DataFrame\n",
    "            m_df.loc[row_count] = [i, movement_id, trajectory, mouse_duration, single_coor]\n",
    "            row_count += 1\n",
    "\n",
    "    # Sort the DataFrame by test number and movement ID\n",
    "    m_df = m_df.sort_values(by=['test_number', 'movement_id'])\n",
    "\n",
    "    # Remove rows where only a single coordinate was recorded (if needed)\n",
    "    m_df = m_df[m_df['single_coor'] == False].reset_index(drop=True)\n",
    "\n",
    "    return m_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATES FEATURES FOR EACH TEST FROM THE DFS GENERATED IN THE PREVIOUS TWO CELLS\n",
    "def feature_gen(k_data, m_data):\n",
    "    columns = ['dwell_avg', 'flight_avg', 'traj_avg']\n",
    "\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "\n",
    "    # for loop calculates average value for the dwell time, flight time and trajectory for each test\n",
    "    for i in range(1, 11):\n",
    "        dwell_list = []\n",
    "        flight_list = []\n",
    "        traj_list = []\n",
    "        for j in k_data.index:\n",
    "            if k_data.at[j, 'test_number'] == i:\n",
    "                dwell_list.append(k_data.at[j, 'dwell_time'])\n",
    "                flight_list.append(k_data.at[j, 'flight_time'])\n",
    "        for j in m_data.index:\n",
    "            if m_data.at[j, 'test_number'] == i:\n",
    "                traj_list.append(m_data.at[j, 'trajectory'])\n",
    "\n",
    "        dwell_list = [j for j in dwell_list if j != 0]\n",
    "        flight_list = [j for j in flight_list if j != 0]\n",
    "        traj_list = [j for j in traj_list if j != 0]\n",
    "\n",
    "        dwell_avg = sum(dwell_list)/len(dwell_list)\n",
    "        flight_avg = sum(flight_list)/len(dwell_list)\n",
    "        traj_avg = sum(traj_list)/len(traj_list)\n",
    "\n",
    "\n",
    "        agg_data = [dwell_avg, flight_avg, traj_avg]\n",
    "\n",
    "        df.loc[i] = agg_data\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3 - Experiments & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary list storage for visualisation\n",
    "acc_list = []\n",
    "fm_list = []\n",
    "# RUNS THE MODEL ON EACH OF THE USER'S DATA\n",
    "\n",
    "for i in range(1, 89):\n",
    "    # stores each of the true data as dictionaries\n",
    "    user_number = i\n",
    "    user_number = str(user_number).zfill(4)\n",
    "    f = open('raw_kmt_dataset/raw_kmt_user_' + user_number + '.json') # loads 1 of the 88 tests from drive\n",
    "    data = json.load(f)\n",
    "    user_details = data['details'] # stores the fabricated card details entered for the user\n",
    "    true_data = data['true_data'] # stores the true data of the .json file\n",
    "    false_data = data ['false_data']\n",
    "    #----------------------------------\n",
    "    true_k_df = dict_key_conversion(true_data) # gets the key events from the json files\n",
    "    false_k_df = dict_key_conversion(false_data)\n",
    "\n",
    "    true_m_df = dict_mouse_conversion(true_data) # gets the mouse events from the json files\n",
    "    false_m_df = dict_mouse_conversion(false_data)\n",
    "    #----------------------------------\n",
    "    true_df = feature_gen(true_k_df, true_m_df) # gets the average dwell, flight and traj for each test\n",
    "    false_df = feature_gen(false_k_df, false_m_df)\n",
    "    true_df['label'] = 1 # adds true or false label to the df for the ML algorithm, 1 == true, 0 == false\n",
    "    false_df['label'] = 0\n",
    "    final_df = pd.concat([true_df, false_df])\n",
    "    final_df = final_df.reset_index(drop=True) # final df that will be used within the ML algorithm\n",
    "    #----------------------------------\n",
    "    y = final_df['label'].tolist() # carries out the train test split and the ML prediction\n",
    "    X = final_df.drop(['label'], axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    predicted_labels = clf.predict(X_test)\n",
    "    clf_rep = classification_report(y_test, predicted_labels, output_dict=True)\n",
    "    acc = clf_rep['accuracy']\n",
    "    fm = clf_rep['weighted avg']['f1-score']\n",
    "    print('User', i)\n",
    "    print('Target Labels', y_test)\n",
    "    print('Predicted Labels', predicted_labels)\n",
    "    print('Accuracy:', acc)\n",
    "    print('Fm:', fm)\n",
    "    print('----------------------------')\n",
    "\n",
    "    acc_list.append(acc)\n",
    "    fm_list.append(fm)\n",
    "\n",
    "\n",
    "\n",
    "final_acc = sum(acc_list)/len(acc_list)\n",
    "final_fm = sum(fm_list)/len(fm_list)\n",
    "\n",
    "\n",
    "print(' ')\n",
    "print('###########################')\n",
    "print('##########RESULTS##########')\n",
    "print('###########################')\n",
    "print('Accuracy:', final_acc)\n",
    "print('F-Measure:', final_fm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 5 - Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df # displays the last df that was passed to the ML algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list.sort()\n",
    "fm_list.sort()\n",
    "ind_class = []\n",
    "for i in range(1, 89):\n",
    "  ind_class.append(i)\n",
    "\n",
    "f = plt.figure(figsize=(14, 7))\n",
    "\n",
    "ax = f.add_subplot(121)\n",
    "ax.plot(ind_class, acc_list, linewidth=3)\n",
    "ax.set_title('(a) Accuraccy Distribution', fontsize=19)\n",
    "ax.set_xlabel('Individual Classifiers', fontsize=17)\n",
    "ax.set_ylim(-.1, 1.1)\n",
    "\n",
    "ax2 = f.add_subplot(122)\n",
    "ax2.plot(ind_class, fm_list, linewidth=3)\n",
    "ax2.set_title('(b) F-Measure Distribution', fontsize=19)\n",
    "ax2.set_xlabel('Individual Classifiers', fontsize=17)\n",
    "ax2.set_ylim(-.1, 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biosure",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
